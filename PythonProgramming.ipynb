{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96a1c41d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter primary key(s), separated by commas: OrderID, CustomerID, DrinkID, FoodID\n",
      "Enter Functional Dependencies in format 'A,B -> C,D' (type 'done' when finished):\n",
      "OrderID -> CustomerID\n",
      "Done\n",
      "Enter Multi-Valued Dependencies in format 'A ->> B' (type 'done' when finished):\n",
      "OrderID ->> DrinkID\n",
      "Done\n",
      "Select the highest normal form to normalize (1: 1NF, 2: 2NF, 3: 3NF, B: BCNF, 4: 4NF, 5: 5NF): 5\n",
      "Enter Join Dependencies in format 'A,B' (type 'done' when finished):\n",
      "OrderID,CustomerID OrderID,DrinkID OrderID,FoodID\n",
      "Done\n",
      "CREATE TABLE Table_1NF (\n",
      "  OrderID INT,\n",
      "  Date VARCHAR(255),\n",
      "  PromocodeUsed VARCHAR(255),\n",
      "  TotalCost VARCHAR(255),\n",
      "  TotalDrinkCost VARCHAR(255),\n",
      "  TotalFoodCost VARCHAR(255),\n",
      "  CustomerID INT,\n",
      "  CustomerName VARCHAR(255),\n",
      "  DrinkID INT,\n",
      "  DrinkName VARCHAR(255),\n",
      "  DrinkSize VARCHAR(255),\n",
      "  DrinkQuantity INT,\n",
      "  Milk VARCHAR(255),\n",
      "  DrinkIngredient VARCHAR(255),\n",
      "  DrinkAllergen VARCHAR(255),\n",
      "  FoodID INT,\n",
      "  FoodName VARCHAR(255),\n",
      "  FoodQuantity INT,\n",
      "  FoodIngredient VARCHAR(255),\n",
      "  FoodAllergen VARCHAR(255),\n",
      "  PRIMARY KEY (OrderID, CustomerID, DrinkID, FoodID)\n",
      ");\n",
      "CREATE TABLE Table_4NF_1 (\n",
      "  OrderID INT,\n",
      "  Date VARCHAR(255),\n",
      "  PromocodeUsed VARCHAR(255),\n",
      "  TotalCost VARCHAR(255),\n",
      "  TotalDrinkCost VARCHAR(255),\n",
      "  TotalFoodCost VARCHAR(255),\n",
      "  CustomerID INT,\n",
      "  CustomerName VARCHAR(255),\n",
      "  DrinkName VARCHAR(255),\n",
      "  DrinkSize VARCHAR(255),\n",
      "  DrinkQuantity INT,\n",
      "  Milk VARCHAR(255),\n",
      "  DrinkIngredient VARCHAR(255),\n",
      "  DrinkAllergen VARCHAR(255),\n",
      "  FoodID INT,\n",
      "  FoodName VARCHAR(255),\n",
      "  FoodQuantity INT,\n",
      "  FoodIngredient VARCHAR(255),\n",
      "  FoodAllergen VARCHAR(255),\n",
      "  PRIMARY KEY (OrderID, CustomerID, DrinkID, FoodID)\n",
      ");\n",
      "CREATE TABLE Table_4NF_2 (\n",
      "  OrderID INT,\n",
      "  DrinkID INT,\n",
      "  PRIMARY KEY (OrderID, DrinkID)\n",
      ");\n",
      "CREATE TABLE Table_5NF_1 (\n",
      "  OrderID INT,\n",
      "  Date VARCHAR(255),\n",
      "  PromocodeUsed VARCHAR(255),\n",
      "  TotalCost VARCHAR(255),\n",
      "  TotalDrinkCost VARCHAR(255),\n",
      "  TotalFoodCost VARCHAR(255),\n",
      "  CustomerID INT,\n",
      "  CustomerName VARCHAR(255),\n",
      "  DrinkID INT,\n",
      "  DrinkName VARCHAR(255),\n",
      "  DrinkSize VARCHAR(255),\n",
      "  DrinkQuantity INT,\n",
      "  Milk VARCHAR(255),\n",
      "  DrinkIngredient VARCHAR(255),\n",
      "  DrinkAllergen VARCHAR(255),\n",
      "  FoodID INT,\n",
      "  FoodName VARCHAR(255),\n",
      "  FoodQuantity INT,\n",
      "  FoodIngredient VARCHAR(255),\n",
      "  FoodAllergen VARCHAR(255),\n",
      "  PRIMARY KEY (OrderID, CustomerID, DrinkID, FoodID)\n",
      ");\n",
      "Normalization results saved to C:\\Users\\dinesh\\OneDrive\\Desktop\\sampledata.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "\n",
    "# Load the input file with encoding specified to handle special characters\n",
    "input_file = r\"C:\\Users\\dinesh\\OneDrive\\Desktop\\Sampledata.csv\"\n",
    "data = pd.read_csv(input_file, encoding='ISO-8859-1')\n",
    "\n",
    "# Define the output file path to save results on the desktop\n",
    "output_file = r\"C:\\Users\\dinesh\\OneDrive\\Desktop\\sampledata.txt\"\n",
    "with open(output_file, 'w') as file:\n",
    "\n",
    "    # Prompt for Primary Keys\n",
    "    primary_key = input(\"Enter primary key(s), separated by commas: \").split(',')\n",
    "    primary_key = [key.strip() for key in primary_key]\n",
    "\n",
    "    # Prompt for Functional Dependencies\n",
    "    FDs = {}\n",
    "    print(\"Enter Functional Dependencies in format 'A,B -> C,D' (type 'done' when finished):\")\n",
    "    while True:\n",
    "        fd_input = input()\n",
    "        if fd_input.lower() == 'done':\n",
    "            break\n",
    "        try:\n",
    "            det, dep = fd_input.split(\"->\")\n",
    "            det_attrs = [attr.strip() for attr in det.split(',')]\n",
    "            dep_attrs = [attr.strip() for attr in dep.split(',')]\n",
    "            FDs[tuple(det_attrs)] = dep_attrs\n",
    "            file.write(f\"{det} -> {dep}\\n\")\n",
    "        except ValueError:\n",
    "            print(\"Invalid format. Please enter in 'A,B -> C,D' format.\")\n",
    "\n",
    "    # Prompt for Multi-Valued Dependencies (MVDs)\n",
    "    MVDs = {}\n",
    "    print(\"Enter Multi-Valued Dependencies in format 'A ->> B' (type 'done' when finished):\")\n",
    "    while True:\n",
    "        mvd_input = input()\n",
    "        if mvd_input.lower() == 'done':\n",
    "            break\n",
    "        try:\n",
    "            det, dep = mvd_input.split(\"->>\")\n",
    "            det = det.strip()\n",
    "            dep = dep.strip()\n",
    "            if det in MVDs:\n",
    "                MVDs[det].append(dep)\n",
    "            else:\n",
    "                MVDs[det] = [dep]\n",
    "            file.write(f\"Multi-Valued Dependency: {det} ->> {dep}\\n\")\n",
    "        except ValueError:\n",
    "            print(\"Invalid format. Please enter in 'A ->> B' format.\")\n",
    "\n",
    "    # Get normalization level from the user\n",
    "    max_normal_form = input(\"Select the highest normal form to normalize (1: 1NF, 2: 2NF, 3: 3NF, B: BCNF, 4: 4NF, 5: 5NF): \")\n",
    "    if max_normal_form in [\"1\", \"2\", \"3\", \"4\", \"5\"]:\n",
    "        max_normal_form = int(max_normal_form)\n",
    "\n",
    "    # Prompt for Join Dependencies (JDs) only if target form is 5NF\n",
    "    JDs = []\n",
    "    if max_normal_form == 5:\n",
    "        print(\"Enter Join Dependencies in format 'A,B' (type 'done' when finished):\")\n",
    "        while True:\n",
    "            jd_input = input()\n",
    "            if jd_input.lower() == 'done':\n",
    "                break\n",
    "            jd = [attr.strip() for attr in jd_input.split(',')]\n",
    "            JDs.append(jd)\n",
    "            file.write(f\"Join Dependency: {', '.join(jd)}\\n\")\n",
    "\n",
    "    # Function to check and convert 1NF\n",
    "    def check_and_convert_1NF(df):\n",
    "        non_atomic_columns = []\n",
    "        for col in df.columns:\n",
    "            if df[col].apply(lambda x: isinstance(x, list)).any():\n",
    "                non_atomic_columns.append(col)\n",
    "                df = df.explode(col)\n",
    "        return df, non_atomic_columns\n",
    "\n",
    "    # Function to check 2NF\n",
    "    def check_2NF(df, primary_key, FDs):\n",
    "        non_prime_attrs = [col for col in df.columns if col not in primary_key]\n",
    "        for det, dep in FDs.items():\n",
    "            if set(det).issubset(primary_key) and any(attr in non_prime_attrs for attr in dep):\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    # Function to check 3NF\n",
    "    def check_3NF(df, primary_key, FDs):\n",
    "        for det, dep in FDs.items():\n",
    "            if set(det) != set(primary_key) and not set(dep).issubset(primary_key):\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    # Function to check BCNF\n",
    "    def check_BCNF(df, primary_key, FDs):\n",
    "        for det, dep in FDs.items():\n",
    "            if not set(det).issubset(primary_key):\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    # Function to check and decompose 4NF based on MVDs\n",
    "    def check_and_decompose_4NF(df, MVDs):\n",
    "        decomposed_tables = []\n",
    "        main_table_columns = list(df.columns)\n",
    "\n",
    "        for det, dep_list in MVDs.items():\n",
    "            for dep in dep_list:\n",
    "                decomposed_table = df[[det, dep]].drop_duplicates()\n",
    "                decomposed_tables.append((decomposed_table, [det, dep]))  # Track primary key for decomposed table\n",
    "                if dep in main_table_columns:\n",
    "                    main_table_columns.remove(dep)\n",
    "\n",
    "                file.write(f\"4NF Decomposition: Created separate table with {det} ->> {dep}\\n\")\n",
    "\n",
    "        main_table = df[main_table_columns].drop_duplicates()\n",
    "        return [(main_table, primary_key)] + decomposed_tables  # Include main table with original primary key\n",
    "\n",
    "    # Function to check and decompose 5NF based on JDs\n",
    "    def check_and_decompose_5NF(df, JDs):\n",
    "        decomposed_tables = []\n",
    "\n",
    "        for jd in JDs:\n",
    "            if set(jd).issubset(df.columns):\n",
    "                decomposed_table = df[jd].drop_duplicates()\n",
    "                decomposed_tables.append((decomposed_table, jd))\n",
    "                file.write(f\"5NF Decomposition: Created separate table for JD ({', '.join(jd)})\\n\")\n",
    "\n",
    "        if not decomposed_tables:\n",
    "            file.write(\"No 5NF decomposition required.\\n\")\n",
    "        return [(df, primary_key)] + decomposed_tables  # Include main table with original primary key\n",
    "\n",
    "    # SQL Query Generator and Schema Representation\n",
    "    def generate_sql_and_schema(table_name, df, primary_keys):\n",
    "        sql_query = f\"CREATE TABLE {table_name} (\\n\"\n",
    "        schema_representation = f\"Table: {table_name}\\nAttributes:\\n\"\n",
    "\n",
    "        for col, dtype in zip(df.columns, df.dtypes):\n",
    "            sql_type = 'INT' if 'int' in str(dtype) else 'VARCHAR(255)'\n",
    "            sql_query += f\"  {col} {sql_type},\\n\"\n",
    "            schema_representation += f\"  - {col} ({sql_type})\\n\"\n",
    "\n",
    "        primary_keys_str = \", \".join(primary_keys)\n",
    "        sql_query += f\"  PRIMARY KEY ({primary_keys_str})\\n);\"\n",
    "        schema_representation += f\"Primary Key(s): {primary_keys_str}\\n\\n\"\n",
    "\n",
    "        # Print and write to file\n",
    "        print(sql_query)\n",
    "        file.write(sql_query + \"\\n\\n\" + schema_representation)\n",
    "\n",
    "    # Main Normalization Process\n",
    "    def normalize_database(df, primary_key, FDs, MVDs, max_normal_form, JDs=[]):\n",
    "        df, non_atomic_columns = check_and_convert_1NF(df)\n",
    "        file.write(\"1NF Applied\\n\" if not non_atomic_columns else f\"Converted columns to atomic: {non_atomic_columns}\\n\")\n",
    "        generate_sql_and_schema('Table_1NF', df, primary_key)\n",
    "\n",
    "        highest_nf = 1\n",
    "        if max_normal_form >= 2 and check_2NF(df, primary_key, FDs):\n",
    "            file.write(\"2NF satisfied.\\n\")\n",
    "            highest_nf = 2\n",
    "        else:\n",
    "            file.write(\"2NF decomposition required.\\n\")\n",
    "\n",
    "        if max_normal_form >= 3 and check_3NF(df, primary_key, FDs):\n",
    "            file.write(\"3NF satisfied.\\n\")\n",
    "            highest_nf = 3\n",
    "        else:\n",
    "            file.write(\"3NF decomposition required.\\n\")\n",
    "\n",
    "        if max_normal_form >= 4 and check_BCNF(df, primary_key, FDs):\n",
    "            file.write(\"BCNF satisfied.\\n\")\n",
    "            highest_nf = \"BCNF\"\n",
    "        else:\n",
    "            file.write(\"BCNF decomposition required.\\n\")\n",
    "\n",
    "        decomposed_tables = [(df, primary_key)]\n",
    "        if max_normal_form >= 4:\n",
    "            decomposed_tables = check_and_decompose_4NF(df, MVDs)\n",
    "            for i, (table, keys) in enumerate(decomposed_tables, start=1):\n",
    "                table_name = f\"Table_4NF_{i}\"\n",
    "                generate_sql_and_schema(table_name, table, keys)\n",
    "            highest_nf = 4 if highest_nf != \"BCNF\" else highest_nf\n",
    "\n",
    "        if max_normal_form == 5:\n",
    "            decomposed_tables = check_and_decompose_5NF(df, JDs)\n",
    "            for i, (table, keys) in enumerate(decomposed_tables, start=1):\n",
    "                table_name = f\"Table_5NF_{i}\"\n",
    "                generate_sql_and_schema(table_name, table, keys)\n",
    "\n",
    "        file.write(f\"The highest normal form achieved for this relation is: {highest_nf}\\n\")\n",
    "\n",
    "    # Execute the normalization\n",
    "    normalize_database(data, primary_key, FDs, MVDs, max_normal_form, JDs)\n",
    "\n",
    "print(f\"Normalization results saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0afc4fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
